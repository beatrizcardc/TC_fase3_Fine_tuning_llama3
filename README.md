# TC_fase3_Fine_tuning_llama3
# ğŸš€ Desafio do Tech Challenge

## ğŸ¯ **Objetivo Principal**
- Executar o **fine-tuning** de um modelo de linguagem (ex.: **LLaMA**, **BERT**, **GPT**) usando o dataset **"The AmazonTitles-1.3MM"**.
- Receber perguntas dos usuÃ¡rios com base em um **contexto** (tÃ­tulo do produto).
- Gerar respostas baseadas na **descriÃ§Ã£o do produto** apÃ³s o fine-tuning.
- ğŸ”—Links Principais:
- https://github.com/beatrizcardc/TC_fase3_Fine_tuning_llama3.git
- https://youtu.be/yFqfh31Yg10
- https://colab.research.google.com/drive/1CZzwU-CrVC8pPMEcnoTDA2CgrvQYtTqE#scrollTo=wvvIfq-5GjW6
---

## ğŸ“Œ **Pipeline Completo do Trabalho**

### ğŸ—‚ï¸ **Escolha do Dataset**
- **Dataset**: The AmazonTitles-1.3MM.
- **Campos**: Utilizar os campos **tÃ­tulo** e **descriÃ§Ã£o** dos produtos.
- ğŸ“¥ **Download e Armazenamento**: Realizar download e armazenar de forma segura no **Google Drive**.

---

### ğŸ§¹ **PreparaÃ§Ã£o do Dataset**
- ğŸ“¤ **Carregar e Inspecionar**: Carregar e revisar os dados.
- ğŸ§¼ **Limpeza**:  
  - Remover linhas com **valores ausentes**.  
  - Remover **duplicatas**.  
  - Normalizar o texto (**remoÃ§Ã£o de caracteres especiais**).  
- ğŸ“‰ **ReduÃ§Ã£o**: Reduzir o tamanho do dataset para **40k registros**.  
- ğŸ”€ **DivisÃ£o**: Separar em **80% treino** e **20% validaÃ§Ã£o**.

---

### ğŸ“Š **AnÃ¡lise de Comprimento**
- ğŸ“ **Analisar Comprimentos** dos prompts e responses.
- ğŸ¯ **Definir max_length**:  
  - **Prompt**: 75 tokens.  
  - **Response**: 450 tokens (para acomodar atÃ© 300 palavras).  
  - **Total**: 525 tokens.  
- ğŸ› ï¸ **Ajuste de Hyperparameters**: Para evitar erros de **Out Of Memory (OOM)** durante o treinamento.

---

### ğŸ”§ **Carregamento do Modelo**
- ğŸ“¥ **Modelo PrÃ©-treinado**: **Llama 3.2-1B** ou similar.
- ğŸ§ª **QuantizaÃ§Ã£o**: Aplicar **8-bit** ou **4-bit** para otimizaÃ§Ã£o de memÃ³ria.
- ğŸ› ï¸ **LoRA**: Configurar **LoRA** para fine-tuning eficiente.

---

### ğŸ”„ **PrÃ©-processamento e TokenizaÃ§Ã£o**
- ğŸ“ **FunÃ§Ã£o de PrÃ©-processamento**:  
  - Combinar **prompts** e **responses** em um Ãºnico formato.  
  - **TokenizaÃ§Ã£o** com truncamento e padding.  
- ğŸ”— **Definir pad_token** como eos_token para compatibilidade.

---

### âš™ï¸ **ConfiguraÃ§Ã£o do Treinamento**
- ğŸ“Š **HiperparÃ¢metros**:  
  - **Epochs**: 3 a 5.  
  - **Batch Size**: 4 - 2 (ajustado para evitar OOM).  
  - **max_length**: 1024 tokens (ou conforme anÃ¡lise).  
  - **Checkpoints**: Salvar checkpoints a cada `save_steps`.  
- ğŸ“Š **Monitoramento**:  
  Usar **WandB** e **TensorBoard** para acompanhar mÃ©tricas como:  
  - `eval_loss`  
  - `validation_loss`  
- ğŸ’¾ **Callbacks**: Salvar os **dois Ãºltimos checkpoints** automaticamente.

---

### ğŸš€ **ExecuÃ§Ã£o do Fine-Tuning**
- â–¶ï¸ **Iniciar Treinamento**: Utilizar o **Trainer** para treinar o modelo.
- ğŸ“‰ **ValidaÃ§Ã£o**: Avaliar durante o treinamento para acompanhar **eval_loss** e **validation_loss**.

---

### ğŸ§ª **AvaliaÃ§Ã£o e GeraÃ§Ã£o de Respostas**
- ğŸ“ **Dados de Teste**: Carregar os dados de teste e o **Ground Truth**.
- ğŸ“¥ **Modelos**: Carregar os modelos **prÃ©-treinado** e **fine-tuned**.
- ğŸ—¨ï¸ **Gerar Respostas**: Produzir respostas para os dados de teste.
- ğŸ”„ **Retreinamento com Ajustes**: Modificar hiperparÃ¢metros e formatar o dataset com title e content.
- ğŸ“ˆ **MÃ©tricas de Desempenho**:  (somente referÃŠncia)
  - **BLEU**  
  - **ROUGE**
![AnÃ¡lise das Respostas v4](https://raw.githubusercontent.com/beatrizcardc/TC_fase3_Fine_tuning_llama3/main/analise_respostas_v4.png)

ğŸ” **ApÃ³s Melhorias da GeraÃ§Ã£o**
![AnÃ¡lise das Respostas v4](https://raw.githubusercontent.com/beatrizcardc/TC_fase3_Fine_tuning_llama3/main/analise2_respostas_v4.png)
 - Como projeto inicial de Fine Tuning e ao reduzir os registros, por limitaÃ§Ãµes tÃ©cnicas, sabemos que nÃ£o teremos respostas tÃ£o robustas. Mas como MVP atingimos o resultado satisfatÃ³rio para alguns prompts.
---

### ğŸ“¦ **Entrega do Projeto**
- ğŸ“„ **Documento Detalhado**:  
  - DescriÃ§Ã£o da **seleÃ§Ã£o e preparaÃ§Ã£o** do dataset.  
  - Processo de **fine-tuning** com parÃ¢metros utilizados.  
- ğŸ’» **CÃ³digo-Fonte**: RepositÃ³rio com o cÃ³digo do **fine-tuning**.  
- ğŸ¥ **VÃ­deo de DemonstraÃ§Ã£o**: Mostrando o modelo gerando respostas.

---



