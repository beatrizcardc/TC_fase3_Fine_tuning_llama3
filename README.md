# TC_fase3_Fine_tuning_llama3
Desafio do Tech Challenge 
Objetivo Principal:  Executar o fine-tuning de um modelo de linguagem (ex.: LLaMA, BERT, GPT) usando o dataset "The AmazonTitles-1.3MM".  
Receber perguntas dos usuÃ¡rios com base em um contexto (tÃ­tulo do produto).  
Gerar respostas baseadas na descriÃ§Ã£o do produto apÃ³s o fine-tuning.

________________________________________
ğŸ“Œ Pipeline Completo do Trabalho
________________________________________
ğŸ—‚ï¸ Escolha do Dataset
â€¢	Dataset: The AmazonTitles-1.3MM.
â€¢	Campos: Utilizar os campos tÃ­tulo e descriÃ§Ã£o dos produtos.
â€¢	ğŸ“¥ Download e Armazenamento: Realizar download e armazenar de forma segura no Google Drive.
________________________________________
ğŸ§¹ PreparaÃ§Ã£o do Dataset
â€¢	ğŸ“¤ Carregar e Inspecionar: Carregar e revisar os dados.
â€¢	ğŸ§¼ Limpeza:
o	Remover linhas com valores ausentes.
o	Remover duplicatas.
o	Normalizar o texto (remoÃ§Ã£o de caracteres especiais).
â€¢	ğŸ“‰ ReduÃ§Ã£o: Reduzir o tamanho do dataset para 40k registros.
â€¢	ğŸ”€ DivisÃ£o: Separar em 80% treino e 20% validaÃ§Ã£o.
________________________________________
ğŸ“Š AnÃ¡lise de Comprimento
â€¢	ğŸ“ Analisar Comprimentos dos prompts e responses.
â€¢	ğŸ¯ Definir max_length:
o	Prompt: 75 tokens.
o	Response: 450 tokens (para acomodar atÃ© 300 palavras).
o	Total: 525 tokens.
â€¢	ğŸ› ï¸ Ajuste de Hyperparameters: Para evitar erros de Out Of Memory (OOM) durante o treinamento.
________________________________________
ğŸ”§ Carregamento do Modelo
â€¢	ğŸ“¥ Modelo PrÃ©-treinado: Llama 3.2-1B ou similar.
â€¢	ğŸ§ª QuantizaÃ§Ã£o: Aplicar 8-bit ou 4-bit para otimizaÃ§Ã£o de memÃ³ria.
â€¢	ğŸ› ï¸ LoRA: Configurar LoRA para fine-tuning eficiente.
________________________________________
ğŸ”„ PrÃ©-processamento e TokenizaÃ§Ã£o
â€¢	ğŸ“ FunÃ§Ã£o de PrÃ©-processamento:
o	Combinar prompts e responses em um Ãºnico formato.
o	TokenizaÃ§Ã£o com truncamento e padding.
â€¢	ğŸ”— Definir pad_token como eos_token para compatibilidade.
________________________________________
âš™ï¸ ConfiguraÃ§Ã£o do Treinamento
â€¢	ğŸ“Š HiperparÃ¢metros:
o	Epochs: 3 a 5.
o	Batch Size: 8 (ajustado para evitar OOM).
o	max_length: 525 tokens (ou conforme anÃ¡lise).
o	Checkpoints: Salvar checkpoints a cada save_steps.
â€¢	ğŸ“Š Monitoramento: Usar WandB e TensorBoard para acompanhar mÃ©tricas como:
o	eval_loss
o	validation_loss
â€¢	ğŸ’¾ Callbacks: Salvar os dois Ãºltimos checkpoints automaticamente.
________________________________________
ğŸš€ ExecuÃ§Ã£o do Fine-Tuning
â€¢	â–¶ï¸ Iniciar Treinamento: Utilizar o Trainer para treinar o modelo.
â€¢	ğŸ“‰ ValidaÃ§Ã£o: Avaliar durante o treinamento para acompanhar eval_loss e validation_loss.
________________________________________
ğŸ§ª AvaliaÃ§Ã£o e GeraÃ§Ã£o de Respostas
â€¢	ğŸ“ Dados de Teste: Carregar os dados de teste e o Ground Truth.
â€¢	ğŸ“¥ Modelos: Carregar os modelos prÃ©-treinado e fine-tuned.
â€¢	ğŸ—¨ï¸ Gerar Respostas: Produzir respostas para os dados de teste.
â€¢	ğŸ“ˆ MÃ©tricas de Desempenho:
o	BLEU
o	ROUGE
________________________________________
ğŸ“¦ Entrega do Projeto
â€¢	ğŸ“„ Documento Detalhado:
o	DescriÃ§Ã£o da seleÃ§Ã£o e preparaÃ§Ã£o do dataset.
o	Processo de fine-tuning com parÃ¢metros utilizados.
â€¢	ğŸ’» CÃ³digo-Fonte: RepositÃ³rio com o cÃ³digo do fine-tuning.
â€¢	ğŸ¥ VÃ­deo de DemonstraÃ§Ã£o: Mostrando o modelo gerando respostas.


